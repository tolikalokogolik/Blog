url = paste0(base_url, job, "&location=", country_name)
remDr$navigate(url)
bodyEl <- remDr$findElement("css", "body")
for (k in 1:30) {
bodyEl$sendKeysToElement(list(key = "end"))
Sys.sleep(2)
}
lol <- remDr$findElements(using = "xpath", "/html/body/div[3]/div/main/section[2]/ul")
#lol$findChildElement("h3")
df_linkedin <- tolower(unlist(lapply(lol, function(x) {x$getElementText()})))
df_linkedin <- df_linkedin %>% str_split("\n") %>% data.frame()
colnames(df_linkedin) <- "output"
df_linkedin <- df_linkedin %>%
filter(grepl(tolower(jobs[i]), output)) %>%
mutate(job_name = jobs[i],
country = countries[j]) %>%
group_by(job_name,
country) %>%
summarise(count = n())
to_return <- bind_rows(to_return,
df_linkedin)
}
}
write.csv("data/linkedin_data.csv", to_return)
} else {
to_return = read.csv("data/linkedin_data.csv")
}
return(to_return)
}
get_jobs_from_linkedin(F, df_salaries)
b
get_jobs_from_linkedin <- function(load = T,
df_salaries){
if (load == F){
jobs <- unique(df_salaries$job_title)
countries <- unique(df_salaries$employee_residence)
rD <- rsDriver(port = free_port(),
browser = "firefox",
extraCapabilities = list(
"moz:firefoxOptions" = list(
args = list('--headless')
)
)
)
remDr <- rD$client
remDr$open()
base_url = "https://www.linkedin.com/jobs/search/?keywords="
to_return = NULL
for (i in 1:length(jobs)){
for (j in 1:length(countries)){
job = str_replace(tolower(jobs[i]), " ", "%20")
country_name = str_replace(country2country_name(countries[j]), " ", "%20")
url = paste0(base_url, job, "&location=", country_name)
remDr$navigate(url)
bodyEl <- remDr$findElement("css", "body")
for (k in 1:30) {
bodyEl$sendKeysToElement(list(key = "end"))
Sys.sleep(1)
}
lol <- remDr$findElements(using = "xpath", "/html/body/div[3]/div/main/section[2]/ul")
#lol$findChildElement("h3")
df_linkedin <- tolower(unlist(lapply(lol, function(x) {x$getElementText()})))
df_linkedin <- df_linkedin %>% str_split("\n") %>% data.frame()
colnames(df_linkedin) <- "output"
df_linkedin <- df_linkedin %>%
filter(grepl(tolower(jobs[i]), output))
if (nrow(df_linkedin)>0){
df_linkedin <- df_linkedin%>%
mutate(job_name = jobs[i],
country = countries[j]) %>%
group_by(job_name,
country) %>%
summarise(count = n())
to_return <- bind_rows(to_return,
df_linkedin)
}
}
}
write.csv("data/linkedin_data.csv", to_return)
} else {
to_return = read.csv("data/linkedin_data.csv")
}
return(to_return)
}
get_jobs_from_linkedin(F, df_salaries)
get_jobs_from_linkedin <- function(load = T,
df_salaries){
if (load == F){
jobs <- unique(df_salaries$job_title)
countries <- unique(df_salaries$employee_residence)
rD <- rsDriver(port = free_port(),
browser = "firefox",
extraCapabilities = list(
"moz:firefoxOptions" = list(
args = list('--headless')
)
)
)
remDr <- rD$client
remDr$open()
base_url = "https://www.linkedin.com/jobs/search/?keywords="
to_return = NULL
for (i in 1:length(jobs)){
for (j in 1:length(countries)){
print(jobs[i], countries[j])
job = str_replace(tolower(jobs[i]), " ", "%20")
country_name = str_replace(country2country_name(countries[j]), " ", "%20")
url = paste0(base_url, job, "&location=", country_name)
remDr$navigate(url)
bodyEl <- remDr$findElement("css", "body")
for (k in 1:30) {
bodyEl$sendKeysToElement(list(key = "end"))
Sys.sleep(1)
}
lol <- remDr$findElements(using = "xpath", "/html/body/div[3]/div/main/section[2]/ul")
#lol$findChildElement("h3")
df_linkedin <- tolower(unlist(lapply(lol, function(x) {x$getElementText()})))
df_linkedin <- df_linkedin %>% str_split("\n") %>% data.frame()
colnames(df_linkedin) <- "output"
df_linkedin <- df_linkedin %>%
filter(grepl(tolower(jobs[i]), output))
if (nrow(df_linkedin)>0){
df_linkedin <- df_linkedin%>%
mutate(job_name = jobs[i],
country = countries[j]) %>%
group_by(job_name) %>%
summarise(count = n())
to_return <- bind_rows(to_return,
df_linkedin)
}
}
}
write.csv("data/linkedin_data.csv", to_return)
} else {
to_return = read.csv("data/linkedin_data.csv")
}
return(to_return)
}
get_jobs_from_linkedin(F, df_salaries)
get_jobs_from_linkedin <- function(load = T,
df_salaries){
if (load == F){
jobs <- unique(df_salaries$job_title)
countries <- unique(df_salaries$employee_residence)
rD <- rsDriver(port = free_port(),
browser = "firefox",
extraCapabilities = list(
"moz:firefoxOptions" = list(
args = list('--headless')
)
)
)
remDr <- rD$client
remDr$open()
base_url = "https://www.linkedin.com/jobs/search/?keywords="
to_return = NULL
for (i in 1:length(jobs)){
for (j in 1:length(countries)){
print(jobs[i], countries[j])
job = str_replace(tolower(jobs[i]), " ", "%20")
country_name = str_replace(country2country_name(countries[j]), " ", "%20")
url = paste0(base_url, job, "&location=", country_name)
remDr$navigate(url)
bodyEl <- remDr$findElement("css", "body")
for (k in 1:30) {
bodyEl$sendKeysToElement(list(key = "end"))
Sys.sleep(1)
}
lol <- remDr$findElements(using = "xpath", "/html/body/div[3]/div/main/section[2]/ul")
#lol$findChildElement("h3")
df_linkedin <- tolower(unlist(lapply(lol, function(x) {x$getElementText()})))
df_linkedin <- df_linkedin %>% str_split("\n") %>% data.frame()
colnames(df_linkedin) <- "output"
df_linkedin <- df_linkedin %>%
filter(grepl(tolower(jobs[i]), output))
if (nrow(df_linkedin)>0){
df_linkedin <- df_linkedin%>%
mutate(job_name = jobs[i],
country = countries[j]) %>%
group_by(job_name) %>%
summarise(count = n())
to_return <- bind_rows(to_return,
df_linkedin)
}
}
}
write.csv("data/linkedin_data.csv", to_return)
} else {
to_return = read.csv("data/linkedin_data.csv")
}
return(to_return)
}
get_jobs_from_linkedin(F, df_salaries)
library(gtrendsR)
library(readr)
library(kaggler)
library(RSelenium)
library(ggplot2)
library(tidyr)
library(dplyr)
library(lemon)
library(scales)
library(ggrepel)
library(wordcloud)
library(RColorBrewer)
library(tidyverse)
library(tidygraph)
library(ggraph)
library(rlang)
library(stringr)
library(rjson)
library(netstat)
#### LIBRARIES ----
library(gtrendsR)
library(readr)
library(kaggler)
library(RSelenium)
library(ggplot2)
library(tidyr)
library(dplyr)
library(lemon)
library(scales)
library(ggrepel)
library(wordcloud)
library(RColorBrewer)
library(tidyverse)
library(tidygraph)
library(ggraph)
library(rlang)
library(stringr)
library(rjson)
library(netstat)
#### GRAPHS SETUP ----
GRAY1 = "#231e20"
GRAY2 = "#414040"
GRAY3 = "#555655"
GRAY4 = "#646369"
GRAY5 = "#76787B"
GRAY6 = "#828282"
GRAY7 = "#929497"
GRAY8 = "#a6a6a5"
GRAY9 = "#bfbebe"
BLUE1 = "#164a7e"
BLUE2 = "#4a81bf"
BLUE3 = "#93b2d7"
BLUE4 = "#94afc5"
BLUE5 = "#21435d"
BLUE6 = "#95b3d7"
RED1 = "#c3514e"
RED2 = "#e6bab7"
RED3 = "#800d00"
GREEN1 = "#0c8040"
GREEN2 = "#9abb59"
GREEN3 = "#31859c"
GREEN4 = "#4bacc5"
GREEN5 = "#93cddd"
ORANGE1 = "#f79747"
ORANGE2 = "#fac090"
theme_swd <- function() {
theme_minimal(base_size = 11, base_family = "Helvetica") +
theme(
panel.grid.major = element_line(size = 0.1, color = GRAY9),
panel.grid.minor = element_blank(),
axis.line = element_line(size = .13, color = GRAY8),
axis.text = element_text(color = GRAY7),
axis.ticks.x = element_line(size = 0.5, color = GRAY8),
axis.ticks.y = element_line(size = 0.5, color = GRAY8),
axis.title = element_text(color = GRAY3),
axis.title.y = element_text(hjust = 1, margin = margin(0, 6, 0, 15, "pt")),
axis.title.x = element_text(hjust = 0, margin = margin(6, 0, 15, 0, "pt")),
plot.subtitle = element_text(color = GRAY4, size= 11),
plot.title = element_text(color = GRAY4, size= 15),
plot.title.position = "plot", # This aligns the plot title to the very left edge
plot.caption = element_text(hjust = 0, color = GRAY6),
plot.caption.position = "plot",
plot.margin = margin(.5,.5,.5,.5,"cm"),
strip.text = element_text(color = GRAY7))
}
#### DATA INGESTION ----
get_google_data <- function(job_title, country, time){
#load data about google trends
df_google <- gtrends(c(job_title),geo = c(country), time = time)
df_google <- list(df_google[["interest_over_time"]], df_google[["related_topics"]])
return(df_google)
}
get_salaries_data <- function(from_kaggle = F){
if (from_kaggle == T){
kgl_auth(creds_file = 'C:/Users/natali00/Downloads/kaggle.json')
response <- kgl_datasets_download_all(owner_dataset = "bryanb/aiml-salaries")
download.file(response[["url"]], "data/temp.zip", mode="wb")
unzip_result <- unzip("data/temp.zip", exdir = "data/", overwrite = TRUE)
}
df_salaries <- read_csv("data/salaries.csv")
return(df_salaries)
}
get_salaries_subdata <- function(df_salaries,
country,
employment_type_,
company_size_,
work_year_,
level){
sdf_salaries <- df_salaries %>%
filter(employee_residence == country,
employment_type %in% employment_type_,
company_size %in% company_size_)
if (work_year_ != "all"){
sdf_salaries2 <- sdf_salaries %>%
filter(work_year == work_year_)
} else {
sdf_salaries2 <- sdf_salaries
}
if (level != "all"){
sdf_salaries3 <- sdf_salaries %>%
filter(experience_level == level)
} else {
sdf_salaries3 <- sdf_salaries
}
return(list(sdf_salaries, sdf_salaries2, sdf_salaries3))
}
get_jobs_from_linkedin <- function(load = T,
df_salaries){
if (load == F){
jobs <- unique(df_salaries$job_title)
countries <- unique(df_salaries$employee_residence)
rD <- rsDriver(port = free_port(),
browser = "firefox",
extraCapabilities = list(
"moz:firefoxOptions" = list(
args = list('--headless')
)
)
)
remDr <- rD$client
remDr$open()
base_url = "https://www.linkedin.com/jobs/search/?keywords="
to_return = NULL
for (i in 1:length(jobs)){
for (j in 1:length(countries)){
job = str_replace(tolower(jobs[i]), " ", "%20")
country_name = str_replace(country2country_name(countries[j]), " ", "%20")
url = paste0(base_url, job, "&location=", country_name)
remDr$navigate(url)
bodyEl <- remDr$findElement("css", "body")
for (k in 1:30) {
bodyEl$sendKeysToElement(list(key = "end"))
Sys.sleep(2)
}
lol <- remDr$findElements(using = "xpath", "/html/body/div[3]/div/main/section[2]/ul")
#lol$findChildElement("h3")
df_linkedin <- tolower(unlist(lapply(lol, function(x) {x$getElementText()})))
df_linkedin <- df_linkedin %>% str_split("\n") %>% data.frame()
colnames(df_linkedin) <- "output"
df_linkedin <- df_linkedin %>%
filter(grepl(tolower(jobs[i]), output)) %>%
mutate(job_name = jobs[i],
country = countries[j]) %>%
group_by(job_name,
country) %>%
summarise(count = n())
to_return <- bind_rows(to_return,
df_linkedin)
}
}
write.csv("data/linkedin_data.csv", to_return)
} else {
to_return = read.csv("data/linkedin_data.csv")
}
return(to_return)
}
country2country_name <- function(country){
country_name <- fromJSON(file = "data/google-trends-locations.json")[[country]]
return(country_name)
}
#### GRAPHS FUNCTIONS ----
plot_exp_level_dist <- function(sdf_salaries2){
plot <- sdf_salaries2 %>%
mutate(experience_level = factor(experience_level, levels =  c("EN", "MI", "SE", "EX")),
color = case_when(experience_level == "EN" ~ BLUE3,
experience_level == "MI" ~ BLUE2,
experience_level == "SE" ~ BLUE1,
T ~ BLUE5)) %>%
ggplot(aes(x = experience_level, fill = color)) +
geom_histogram(stat="count") +
theme_swd() +
scale_fill_identity() +
ylab("Count of workers") +
xlab("Experience level") +
ggtitle("Distribution of experience levels")
return(plot)
}
plot_salary_dist <- function(sdf_salaries, sdf_salaries2){
salary_range <- c(min(sdf_salaries$salary_in_usd),
max(sdf_salaries$salary_in_usd))
plot <- sdf_salaries2 %>%
ggplot(aes(x = salary_in_usd, y = ..density.. , fill = BLUE2)) +
geom_histogram() +
geom_density(linewidth = 1.2,
linetype = 2,
colour = BLUE5,
alpha=0.3,
fill = BLUE5) +
xlim(salary_range) +
theme_swd() +
scale_fill_identity() +
ylab("Density") +
xlab("Salary") +
ggtitle("Distribution of salaries") +
scale_x_continuous(labels = label_dollar())
return(plot)
}
plot_wordcloud <- function(sdf_salaries2){
words <- sdf_salaries2 %>%
group_by(job_title) %>%
summarise(n = n())
plot <- wordcloud(words = words$job_title,
freq = words$n,
colors=brewer.pal(9,"Blues")[5:length(brewer.pal(9,"Blues"))],
random.order=FALSE,
rot.per=0.35,
min.freq = 1)
return(plot)
}
plot_search_time <- function(data){
plot <- data  %>%
ggplot(aes(x=date, y=hits, color=BLUE5)) +
geom_line() +
theme_swd() +
scale_color_identity()+
ylab("Hits") +
xlab("Date") +
ggtitle("Google search engine usage")
return(plot)
}
plot_search_related_topics <- function(data, job_title){
node <- data.frame(topics = c(unique((data %>%
filter(!is.na(as.numeric(subject))))$value),
job_title))
edge <- data %>%
filter(!is.na(as.numeric(subject))) %>%
mutate(subject = as.numeric(subject)) %>%
rename(from = keyword,
to = value) %>%
select(from, to, subject)
g <- tbl_graph(nodes = node,
edges = edge,
node_key = "topics",
directed = F)
plot <- ggraph(g, layout = "kk") +
geom_node_point() +
geom_edge_link(aes(width = subject, color = subject))+
geom_node_label(aes(label = topics)) +
xlim(-4,5) +
theme_void() +
theme(legend.position = "None") +
scale_edge_color_gradient(low = BLUE3, high = BLUE1)
return(plot)
}
df_salaries <- get_salaries_data()
get_jobs_from_linkedin <- function(load = T,
df_salaries){
if (load == F){
jobs <- unique(df_salaries$job_title)
countries <- unique(df_salaries$employee_residence)
rD <- rsDriver(port = free_port(),
browser = "firefox",
extraCapabilities = list(
"moz:firefoxOptions" = list(
args = list('--headless')
)
)
)
remDr <- rD$client
remDr$open()
base_url = "https://www.linkedin.com/jobs/search/?keywords="
to_return = NULL
for (i in 1:length(jobs)){
for (j in 1:length(countries)){
print(jobs[i], countries[j])
job = str_replace(tolower(jobs[i]), " ", "%20")
country_name = str_replace(country2country_name(countries[j]), " ", "%20")
url = paste0(base_url, job, "&location=", country_name)
remDr$navigate(url)
bodyEl <- remDr$findElement("css", "body")
for (k in 1:30) {
bodyEl$sendKeysToElement(list(key = "end"))
Sys.sleep(1)
}
lol <- remDr$findElements(using = "xpath", "/html/body/div[3]/div/main/section[2]/ul")
#lol$findChildElement("h3")
df_linkedin <- tolower(unlist(lapply(lol, function(x) {x$getElementText()})))
df_linkedin <- df_linkedin %>% str_split("\n") %>% data.frame()
colnames(df_linkedin) <- "output"
df_linkedin <- df_linkedin %>%
filter(grepl(tolower(jobs[i]), output))
if (nrow(df_linkedin)>0){
df_linkedin <- df_linkedin%>%
mutate(job_name = jobs[i],
country = countries[j]) %>%
group_by(job_name) %>%
summarise(count = n())
to_return <- bind_rows(to_return,
df_linkedin)
}
}
}
write.csv("data/linkedin_data.csv", to_return)
} else {
to_return = read.csv("data/linkedin_data.csv")
}
return(to_return)
}
get_jobs_from_linkedin(F, df_salaries)
